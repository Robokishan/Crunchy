version: '3'
services:

  # tor didn't worked for crunchbase
  # tor-proxy:
  #   image: "dperson/torproxy:latest"
  #   restart: always
  #   ports:
  #     - "9050:9050"
  #     - "9051:9051"
  #     - "8118:8118"
  #   environment:
  #     TORUSER: 'crunchbase'
  #     TOR_NewCircuitPeriod: 2000
  #     EXITNODE: 1
  #     BW: 1000000
  #     PASSWORD: 'admin'
  # tor-ipv6:
  #   image: "chriswayg/tor-server"
  #   restart: always
  #   ports:
  #     - "9053:9001"
  #     - "9054:9030"
  #   environment:
  #     TOR_NICKNAME: 'crunchbase'

  # tor-bart:
  #   container_name: 'tor-bart'
  #   image: 'pickapp/tor-proxy:latest'
  #   ports:
  #     - '9990:8888'
  #   environment:
  #     - IP_CHANGE_SECONDS=60

  crawler-crunchy:
    container_name: crawler-crunchy
    image: "index.docker.io/robokishan/crunchy:crawler"
    command: bash -c "./wait-for-it.sh rabbitmq:5672 -t 0 -- python3 ./go-crunchy-cb.py"
    restart: always
    env_file:
      - ${ENV_FILE}
    depends_on:
      rabbitmq:
        condition: service_healthy
    logging:
      driver: fluentd
      options:
        fluentd-address: 127.0.0.1:24224
        tag: "docker.{{.Name}}"
    links:
      - rabbitmq

  crawler-tracxn:
    container_name: crawler-tracxn
    image: "index.docker.io/robokishan/crunchy:crawler"
    command: bash -c "./wait-for-it.sh rabbitmq:5672 -t 0 -- python3 ./go-crunchy-tracxn.py"
    restart: always
    env_file:
      - ${ENV_FILE}
    depends_on:
      rabbitmq:
        condition: service_healthy
    logging:
      driver: fluentd
      options:
        fluentd-address: 127.0.0.1:24224
        tag: "docker.{{.Name}}"
    links:
      - rabbitmq

  api:
    container_name: api
    image: "index.docker.io/robokishan/crunchy:rest"
    restart: always
    # command: bash -c "python manage.py runserver 0.0.0.0:8000"
    command: bash -c "./wait-for-it.sh rabbitmq:5672 -t 0 -- python manage.py runserver 0.0.0.0:8000"
    ports:
      - "8001:8000"
    env_file:
      - ${ENV_FILE}
    depends_on:
      rabbitmq:
        condition: service_healthy
    links: 
        - rabbitmq

  databucket-crunchy:
    container_name: bucket-crunchy
    image: "index.docker.io/robokishan/crunchy:rest"
    command: bash -c "./wait-for-it.sh rabbitmq:5672 -t 0 -- python manage.py gather_data_from_crunchy"
    restart: always
    env_file:
      - ${ENV_FILE}
    depends_on:
      rabbitmq:
        condition: service_healthy
    links:
      - rabbitmq
    logging:
      driver: fluentd
      options:
        fluentd-address: 127.0.0.1:24224
        tag: "docker.{{.Name}}"

  databucket-tracxn:
    container_name: bucket-tracxn
    image: "index.docker.io/robokishan/crunchy:rest"
    command: bash -c "./wait-for-it.sh rabbitmq:5672 -t 0 -- python manage.py gather_data_from_tracxy"
    restart: always
    env_file:
      - ${ENV_FILE}
    depends_on:
      rabbitmq:
        condition: service_healthy
    links:
      - rabbitmq
    logging:
      driver: fluentd
      options:
        fluentd-address: 127.0.0.1:24224
        tag: "docker.{{.Name}}"

  ui:
    container_name: ui
    image: "index.docker.io/robokishan/crunchy:ui"
    restart: always
    ports:
      - "5051:80"
    env_file:
      - ${ENV_FILE}
    depends_on:
      - api
  
  aichat:
    container_name: aichat
    image: "index.docker.io/robokishan/crunchy:aichat"
    restart: always
    ports:
      - "5052:7860"
    env_file:
      - ${ENV_FILE}
    depends_on:
      - neo4j
      # - ollama-service

  rabbitmq:
    container_name: queue
    image: "rabbitmq:3.12.6-management-alpine"
    restart: always
    hostname: queue
    ports:
      - "15672:15672"
      - "5672:5672"
    environment:
      RABBITMQ_DEFAULT_USER: admin
      RABBITMQ_DEFAULT_PASS: admin
    volumes:
      - rabbitmq_data:/var/lib/rabbitmq/
      - rabbitmq_log:/var/log/rabbitmq
    healthcheck:
      test: [ "CMD", "rabbitmq-diagnostics", "check_running" ]
      interval: 5s
      timeout: 10s
      retries: 5
    depends_on:
      - fluentd

  fluentd:
    container_name: fluentd
    image: robokishan/crunchy:fluentd
    build: ./fluentd
    restart: always
    ports:
      - "24224:24224"       # Fluentd's TCP port
      - "24224:24224/udp"   # Fluentd's UDP port
    volumes:
      - ./fluentd:/fluentd/etc  # Mount Fluentd configuration
      - ./logs:/fluentd/logs    # Volume to store Fluentd output logs
    environment:
      - NEW_RELIC_LICENSE_KEY=${NEW_RELIC_LICENSE_KEY}
      - FLUENTD_CONF=fluentd.conf  # Use custom configuration
      - MALLOC_ARENA_MAX=2
      - LD_PRELOAD=""
    
  # portainer:
  #   container_name: portainer
  #   image: 'portainer/portainer:latest'
  #   logging:
  #     options: {max-size: 5m}
  #   ports:
  #     - '9000:9000'
  #     - '8000:8000'
  #   restart: always
  #   volumes:
  #     - '/var/run/docker.sock:/var/run/docker.sock'
  #     - 'portainer_data:/data'

  watchtower:
    command: 'crawler-crunchy crawler-tracxn api ui bucket-crunchy bucket-tracxn --interval 3600 --debug --remove-volumes --cleanup --include-restarting'
    container_name: watchtower
    environment:
      - REPO_USER=${DOCKER_USERNAME}
      - REPO_PASS=${DOCKER_PASSWORD}
    image: 'containrrr/watchtower:1.2.1'
    logging:
      options: {max-size: 5m}
    privileged: true
    restart: always
    volumes:
      - '/var/run/docker.sock:/var/run/docker.sock'
  neo4j:
    container_name: graphdb
    image: "neo4j:5.23.0-community-bullseye"
    restart: always
    ports:
      - "7474:7474"
      - "7687:7687"
    environment:
      - NEO4J_AUTH=neo4j/Abcd@1234
      - NEO4J_apoc_export_file_enabled=true
      - NEO4J_apoc_import_file_enabled=true
      - NEO4J_apoc_import_file_use__neo4j__config=true
      - NEO4J_PLUGINS=["apoc"]
    volumes:
      - neo4j_data:/data
      - neo4j_logs:/logs
      - neo4j_import:/var/lib/neo4j/import
      - neo4j_plugins:/plugins

  # ollama-service:
  #   container_name: ollama_pi_local
  #   image: ollama/ollama:latest
  #   volumes:
  #     - ./ollama:/root/.ollama
  #   ports:
  #     - 11434:11434
  
  # download-model:
  #   image: curlimages/curl:8.6.0
  #   entrypoint: ["curl", "ollama-service:11434/api/pull", "-d", '{"name": "llama3"}']
  #   # You can use other models
  #   #entrypoint: ["curl", "ollama-service:11434/api/pull", "-d", '{"name": "phi"}']
  #   #entrypoint: ["curl", "ollama-service:11434/api/pull", "-d", '{"name": "orca-mini:7b"}']
  #   depends_on:
  #     ollama-service:
  #       condition: service_started

    
  # mongodb:
  #   image: "mongo:5.0"
  #   restart: always
  #   ports:
  #     - "27017:27017"

volumes:
  rabbitmq_data:
  rabbitmq_log:
  portainer_data:
  neo4j_data:
  neo4j_logs:
  neo4j_import:
  neo4j_plugins: